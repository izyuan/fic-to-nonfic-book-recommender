{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d8406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import asyncio\n",
    "from langdetect import detect\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "import gensim.downloader as api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89cf2d6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad link or error, The Diary of a Young Girl (Mass Market Paperback) because of Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=121.0.6167.140)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF62E425E42+3538674]\n",
      "\t(No symbol) [0x00007FF62E044C02]\n",
      "\t(No symbol) [0x00007FF62DEF5AEB]\n",
      "\t(No symbol) [0x00007FF62DED288C]\n",
      "\t(No symbol) [0x00007FF62DF65DD7]\n",
      "\t(No symbol) [0x00007FF62DF7B40F]\n",
      "\t(No symbol) [0x00007FF62DF5EE53]\n",
      "\t(No symbol) [0x00007FF62DF2F514]\n",
      "\t(No symbol) [0x00007FF62DF30631]\n",
      "\tGetHandleVerifier [0x00007FF62E456CAD+3738973]\n",
      "\tGetHandleVerifier [0x00007FF62E4AC506+4089270]\n",
      "\tGetHandleVerifier [0x00007FF62E4A4823+4057299]\n",
      "\tGetHandleVerifier [0x00007FF62E175C49+720121]\n",
      "\t(No symbol) [0x00007FF62E05126F]\n",
      "\t(No symbol) [0x00007FF62E04C304]\n",
      "\t(No symbol) [0x00007FF62E04C432]\n",
      "\t(No symbol) [0x00007FF62E03BD04]\n",
      "\tBaseThreadInitThunk [0x00007FF87274257D+29]\n",
      "\tRtlUserThreadStart [0x00007FF8731AAA58+40]\n",
      ", retrying... \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 88\u001b[0m\n\u001b[0;32m     87\u001b[0m book_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.goodreads.com/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m title[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 88\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(book_page)\n\u001b[0;32m     89\u001b[0m bp_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ieyua\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[1;32mc:\\Users\\ieyua\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\ieyua\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=121.0.6167.140)\nStacktrace:\n\tGetHandleVerifier [0x00007FF62E425E42+3538674]\n\t(No symbol) [0x00007FF62E044C02]\n\t(No symbol) [0x00007FF62DEF5AEB]\n\t(No symbol) [0x00007FF62DED288C]\n\t(No symbol) [0x00007FF62DF65DD7]\n\t(No symbol) [0x00007FF62DF7B40F]\n\t(No symbol) [0x00007FF62DF5EE53]\n\t(No symbol) [0x00007FF62DF2F514]\n\t(No symbol) [0x00007FF62DF30631]\n\tGetHandleVerifier [0x00007FF62E456CAD+3738973]\n\tGetHandleVerifier [0x00007FF62E4AC506+4089270]\n\tGetHandleVerifier [0x00007FF62E4A4823+4057299]\n\tGetHandleVerifier [0x00007FF62E175C49+720121]\n\t(No symbol) [0x00007FF62E05126F]\n\t(No symbol) [0x00007FF62E04C304]\n\t(No symbol) [0x00007FF62E04C432]\n\t(No symbol) [0x00007FF62E03BD04]\n\tBaseThreadInitThunk [0x00007FF87274257D+29]\n\tRtlUserThreadStart [0x00007FF8731AAA58+40]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 115\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad link or error, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, retrying... \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 115\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success: \n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to retrieve data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%ProgramFiles%\\Google\\Chrome\\Application\\chrome.exe\n",
    "username = 'helloworldtesting59@gmail.com'\n",
    "password = 'securepassword'\n",
    "#setting up webdriver\n",
    "webdriver_path = '%ProgramFiles%\\Google\\Chrome\\Application\\chrome.exe'\n",
    "\n",
    "\n",
    "#chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\")\n",
    "#chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "\n",
    "#loggin in \n",
    "login_url = 'https://www.goodreads.com/ap/signin?language=en_US&openid.assoc_handle=amzn_goodreads_web_na&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.mode=checkid_setup&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&openid.pape.max_auth_age=0&openid.return_to=https%3A%2F%2Fwww.goodreads.com%2Fap-handler%2Fsign-in&siteState=ba99ed98e3cb4430399c0bc24e911cce'\n",
    "driver.get(login_url)\n",
    "#seeing if already logged in. \n",
    "try: \n",
    "    driver.find_element(by.CLASS_NAME, 'gr-h3 gr-h3--noTopMargin')\n",
    "    print('already logged in, skipping login proccess')\n",
    "#fuck this\n",
    "except: \n",
    "    #looking for where to login \n",
    "    username_field = driver.find_element(By.NAME, \"email\")\n",
    "    password_field = driver.find_element(By.NAME, \"password\")\n",
    "    #logging in\n",
    "    username_field.send_keys(username)\n",
    "    password_field.send_keys(password)\n",
    "    password_field.send_keys(Keys.RETURN)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "#beautifulsoup addiiton\n",
    "url = 'https://www.goodreads.com/shelf/show/non-fiction'\n",
    "page_number = 1\n",
    "\n",
    "\n",
    "#creating lists\n",
    "title_list = []\n",
    "author_list = []\n",
    "avgrating_list = []\n",
    "number_of_ratings = []\n",
    "pub_date_list = []\n",
    "review_list = []\n",
    "synopsis_list = []\n",
    "genre_list = []\n",
    "    \n",
    "#page numbers \n",
    "while page_number <= 1:\n",
    "    \n",
    "    #beautifulSoup \n",
    "    page = driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    #what im tryna extract\n",
    "    next_page = soup.find('a', class_ = 'next_page')\n",
    "    titles = soup.find_all('a', class_ = 'bookTitle')\n",
    "    author_name = soup.find_all('a', class_ ='authorName')\n",
    "    avg_rating = soup.find_all('span', class_ ='greyText smallText')\n",
    "    \n",
    "    \n",
    "    #checking to see if I got what i need\n",
    "    for title, author, average_rating in zip(titles, author_name, avg_rating):\n",
    "        #breaking down the avg_rating into rating list, rating avg,number of rating, publish date \n",
    "        clean_list = average_rating.get_text().replace('\\n', '').strip()\n",
    "        result_re = re.split(r'\\s*â€”\\s*', clean_list)\n",
    "        \n",
    "        \n",
    "        title_list.append(title.get_text())\n",
    "        author_list.append(author.get_text())\n",
    "        avgrating_list.append(float(result_re[0].split()[2]))\n",
    "        number_of_ratings.append(int(result_re[1].split()[0].replace(',','')))\n",
    "        try:\n",
    "            publication_date = int(result_re[2].split()[-1])\n",
    "            pub_date_list.append(publication_date)\n",
    "        except ValueError:\n",
    "            pub_date_list.append('errorlololol')\n",
    "\n",
    "    for title in titles:    \n",
    "        #setting up restart loop\n",
    "        max_retries = 3\n",
    "        success = False\n",
    "        #extracting reviews + synopsis\n",
    "        for attempt in range(3):\n",
    "            try: \n",
    "                book_page = 'https://www.goodreads.com/' + title['href']\n",
    "                driver.get(book_page)\n",
    "                bp_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                #reviews        \n",
    "                reviews = bp_soup.find_all('section', class_='ReviewText__content')\n",
    "                reviews_str = '!121!'.join([rev.get_text().strip() for rev in reviews if detect(rev.get_text()) == 'en'])\n",
    "                review_list.append(reviews_str)\n",
    "\n",
    "                # synopsis\n",
    "                synopsis = bp_soup.find('span', class_='Formatted')\n",
    "                synopsis_list.append(synopsis.get_text())\n",
    "\n",
    "                # genres\n",
    "                genre_section = bp_soup.find('div', class_='BookPageMetadataSection__genres')\n",
    "                if genre_section:\n",
    "                    genre_elements = genre_section.find_all('a')\n",
    "                    genres = [genre.get_text(strip=True) for genre in genre_elements]\n",
    "                    genre_list.append(genres)\n",
    "                else: \n",
    "                    print('failed to extract genre info')\n",
    "                    genre_list.append('errorlololol')\n",
    "\n",
    "                success = True\n",
    "                break\n",
    "\n",
    "            except Exception as e: \n",
    "                print(f'bad link or error, {title.get_text()} because of {e}, retrying... ')\n",
    "                time.sleep(2)\n",
    "\n",
    "        if not success: \n",
    "            print(f'failed to retrieve data for {title.get_text()}  ')\n",
    "            genre_list.append(\"errorlololol\")\n",
    "            synopsis_list.append('errorlololol')\n",
    "            review_list.append('errorlolololol')\n",
    "\n",
    "            time.sleep(0.6)\n",
    "\n",
    "\n",
    "            \n",
    "    #next page\n",
    "    if next_page:\n",
    "        url = 'https://www.goodreads.com/' + next_page['href']\n",
    "        page_number += 1\n",
    "        print(f'went to page {page_number}')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        break\n",
    "\n",
    "driver.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d731a0a",
   "metadata": {},
   "source": [
    "webscraping done!, from there need to check to make sure the length of all lists are the same so we can establish a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "dictionary = {'Book Title': title_list, \n",
    "            'Author': author_list, \n",
    "            'Average Rating': avgrating_list,\n",
    "            'Total Rating': number_of_ratings,\n",
    "            'Publish Date': pub_date_list, \n",
    "            'Synopsis': synopsis_list,\n",
    "            'Review': review_list, \n",
    "            'Genres': genre_list\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0d15a",
   "metadata": {},
   "source": [
    "fixing data lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce13b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dictionary)\n",
    "df.to_csv('goodreads_nonfiction_books.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9340e0f",
   "metadata": {},
   "source": [
    "#ARCHIVES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
